\section{Taylor and Maclaurin Series}
\begin{itemize}
    \item Recall that the power series can be written as:
    \begin{equation}
        f(x) = c_0 + c_1(x-a) + c_2(x-a)^2 + \cdots 
    \end{equation}
    for $|x-a|<R$, we note that $f(a)=c_0$. However, if we take the derivative:
    \begin{equation}
        f'(x) = c_1+2c_2(x-a)+3c_3(x-a)^2 + \cdots 
    \end{equation}
    and we similarly get $f'(a)=c_1$. For the second derivative:
    \begin{equation}
        f''(x) = 2c_2 + 6c_3(x-a) + \cdots 
    \end{equation}
    we get $f''(a)=2c_2$.
    \item In general:
    \begin{equation}
        f^(n)(a) = n!c_n
    \end{equation}
    \begin{theorem}
        If $f(x)$ has a power series representation about $a$:
        \begin{equation}
            f(x)= \sum_{n=0}^\infty c_n (x-a)^n
        \end{equation}
        with $|x-a|<R$. Then the coefficients of the series are $c_n = \frac{f^{(n)(a)}}{n!}$
    \end{theorem}
    \item For a Taylor series of $f$ about $a$, we have:
    \begin{equation}
        f(x) = \sum_{n=0}^\infty \frac{f^{(n)}(a)}{n!}(x-a)^n = f(a) + \frac{f'(a)(x-a)}{1!} + \frac{f''(a)(x-a)^2}{2!} + \cdots
    \end{equation}
    \item For the Maclaurin Series, it is simply a Taylor series taken at $x=a$:
    \begin{equation}
        f(x) = \sum_{n=0}^\infty \frac{f^{(n)}(0)}{n!}x^n = f(0) + \frac{f'(0)}{1!}x+\frac{f''(0)}{2!}x^2+\cdots
    \end{equation}
    \begin{definition}
        A definition is called \textbf{analytic at a} if it can be represented as a power series about $a$.
    \end{definition}
    \begin{example}
        Let us attempt to write out the Maclaurin series of $f(x)=e^x$. First note that:
        \begin{equation}
            f'(x)=e^x=f''(x)=f'''(x)=f^{(n)}(x)
        \end{equation}
        Therefore: $f^{(n)}(0)=e^0=1$. Therefore, we can write it as the series:
        \begin{equation}
            e^x = \sum_{n=0}^\infty \frac{x^n}{n!} = 1+x+\frac{x^2}{2!}+\frac{x^3}{3!}+\cdots
        \end{equation}
        We can check that this converges using the ratio test. Let $a_n=\frac{x^n}{n!}$. Then:
        \begin{equation}
            \left|\frac{a_{n+1}}{a_n}\right| = \left|\frac{x^{n+1}}{(n+1)!} \cdot \frac{n!}{x^n}\right| = \frac{|x|}{n+1}
        \end{equation}
        which approaches zero as $n\to\infty$. As a result, $R=\infty$
    \end{example}
    \item We ask ourselves the question: When is it true that $f(x)=\sum_{n=0}^\infty \frac{f^{(n)}(a)}{n!}(x-a)^n$
    \begin{definition}
        The nth degree Taylor polynomial of $f$ about $a$ can be written as:
        \begin{equation}
            T_n(x) = \sum_{i=0}^n \frac{f^{(i)}(a)}{i!}(x-a)^i = f(a) + \frac{f'(a)}{1!}(x-a)+\cdots + \frac{f^{(n)}(a)}{n!}(x-a)^n
        \end{equation}
    \end{definition}
    \begin{example}
        Let us take a look at $e^x$ about $a=0$. Then the first, second, third degree series can be written as:
        \begin{align}
            T_1(x) &=  1+x \\ 
            T_2(x) &= 1+x+\frac{x^2}{2} \\ 
            T_3(x) &= 1+x+\frac{x^2}{2}+\frac{x^3}{3!}
        \end{align}
        We can then define the remainder function as:
        \begin{equation}
            R_n(x)=f(x)-T_n(x)
        \end{equation}
    \end{example}
    \begin{theorem}
        If $f(x)=T_n(x)+R_n(x)$ and $\lim_{n\to\infty} R_n(x)=0$ for $|x-a|<R$. Then $f$ is equal to the sum of its Taylor series.
        \vspace{2mm}

        Given that $f$ has $n+1$ continuous derivatives on an open interval $I$ containing $a$, tyhen for all $x\in I$:
        \begin{equation}
            f(x) = f(a)+f'(a)(x-a)+\frac{f''(a)(x-a)^2}{2!}+\cdots + \frac{f^{(n)}(a)(x-a)^n}{n!}+R_n(x)
        \end{equation}
        where
        \begin{equation}
            R_n(x) = \frac{1}{n!}\int_a^x f^{(n+1)}(t)(x-t)^n \dd{t}
        \end{equation}
        \begin{proof}
            Consider the fundamental theorem of calculus:
            \begin{equation}
                \int_a^b f'(t) \dd{t} = f(b)-f(a)
            \end{equation}
            Suppose we evaluate this via integration by parts:
            \begin{align*}
                u = f'(t) && \dd{v}=\dd{t} \\ 
                \dd{u}=f''(t) && v = t-b
            \end{align*}
            This gives:
            \begin{align}
                \int_a^b f'(t) \dd{t} &= [f'(t)(t-b)]^b_a - \int_a^b f''(t)(t-b)\dd{t} \\ 
                &= (b-a)f'(a) + \int_a^b (b-t)fL''(t)\dd{t}
            \end{align}
            We integrate by parts again:
            \begin{align}
                u=f''(t) && \dd{v}=(b-t)\dd{t} \\ 
                \dd{u}=f'''(t)\dd{t} && v = -\frac{(b-t)^2}{2}
            \end{align}
            which gives:
            \begin{align}
                \int_a^b f^n(t) (b-t)\dd{t} = \left[-\frac{(b-t)^2}{2}f''(t)\right]^b_a+\int_a^b \frac{(b-t)^2}{2}f'''(t)\dd{t}
            \end{align}
            If we continue this a total of $n$ times, then we eventually get:
            \begin{equation}
                \int_a^b f'(t) \dd{t} = (b-a)f'(a) + \frac{(b-a)^2}{2!}f''(a) + \frac{(b-a)^3}{3!}f''(a) + \cdots + \frac{(b-a)^n}{n!}f^{(n)}(a) + \int_a^b \frac{(b-t)^n}{n!}f^{n+1}(t)\dd{t}
            \end{equation}
            However, remember that this integration is equal to $f(b)-f(a)$. If we let $x=b$, then we get:
            \begin{equation}
                f(x) = f(a)+(x-a)f'(a)+\frac{(x-a)^2}{2!}f''(a)+\cdots + \frac{(x-a)^n}{n!}f^{(n)}(a) + R_n(x)
            \end{equation}
            where from our previous work, we have
            \begin{equation}
                R_n(x) = \int_a^x \frac{(x-t)^n}{n!}f^{n+1}(t) \dd{t}
            \end{equation}
        \end{proof}
    \end{theorem}
    \item For $|f^{(n+1)}(t)| \le M$ for $a<t < x$ we can bound the remainder function by:
    \begin{equation}
        |R_n(x)| \le \left|\int_0^x \frac{M(x-t)^n}{n!}\dd{t}\right| = \left|M\left[\frac{(x-t)^{n+1}}{(n+1)!}\right]^x_a\right| = M\frac{|x-a|^{n+1}}{(n+1)!}
    \end{equation}
    \item If we instead use the MVT, we can obtain a slightly different expression for the reaminder:
    \begin{equation}
        R_n(x) = \frac{f^{n+1}(c)(x-a)^{n+1}}{(n+1)!}
    \end{equation}
    with $a<c<x$.
    \begin{example}
        Suppose we wish to continue the proof that $e^x$ is indeed equal to the sum of its Taylor series, we note again that $f^{(n+1)}(t)=e^t$. For $x>0$, we can pick an $x$ such that $0<t<x$ where $e^t<e^x$. The remainder can then be written as:
        \begin{equation}
            R_n(x) < \frac{e^xx^{n+1}}{(n+1)!}
        \end{equation}
        As $n\to\infty$, the remainder approaches zero and as a result:
        \begin{equation}
            e^x = \sum_{n=0}^\infty \frac{x^n}{n!}
        \end{equation}
        for all $x$ is a true statement.
    \end{example}
    \begin{example}
        Let us now find the Maclaurin series for $\cos x$. We have:
        \begin{align}
            f(x)=\cos x && f(0)=1 \\ 
            f'(x)=-\sin x && f'(0)=0 \\ 
            f''(x) = -\cos x && f''(0)=-1 \\ 
            f'''(x) = \sin x && f'''(0)= 0 \\ 
            f^{(4)}(x) = \cos x && f(0) = 1
        \end{align}
        and it repeats. Therefore, we propose that:
        \begin{align}
            \cos x &= f(0)+f'(0)x+\frac{f''(0)x^2}{2}+\cdots \\ 
            &= 1-\frac{x^2}{2!}+\frac{x^4}{4!}-\frac{x^6}{6!}+\cdots \\ 
            &= \sum_{n=0}^\infty (-1)^n \frac{x^{2n}}{(2n)!}
        \end{align}
        We can use the ratio test to show that the radius of convergence is $R=\infty$. Finally, we need to prove that this sum is $\cos x$. We note that:
        \begin{equation}
            |f^{n+1}(t)| = \pm \cos t \text{ or } \pm \sin t \le 1
        \end{equation}
        so we can bound the remainder by:
        \begin{equation}
            |R_n(x)| \le \left|\frac{Mx^{n+1}}{(n+1)!}\right| = \left|\frac{x^{n+1}}{(n+1)!}\right|
        \end{equation}
    \end{example}
    \item An important idea is that it does not matter where the coefficients in the power series expansion comes from. There is only one unique set of coefficients so if one possible set is found, then it is the only set.
    \begin{example}
        Let us find the Maclaurin series for $\sin x$:
        \begin{align}
            \sin x &= -\frac{d}{dx}\cos x \sum_{n=0}^\infty (-1)^n \frac{x^{2n}}{(2n)!} \\ 
            &= \sum_{n=1}^\infty (-1)^{n-1} 2n\frac{x^{2n-1}}{2n!} \\ 
            &= \sum_{n=0}^\infty (-1)^n \frac{x^{2n+1}}{(2n+1)!}
        \end{align}
    \end{example}
    \begin{example}
        Consider the function $x\sin x$. The power expansion is thus:
        \begin{equation}
            x\sin x = \sum_{n=0}^\infty (-1)^n \frac{x^{2n+2}}{(2n+1)!}
        \end{equation}
    \end{example}
    \begin{example}
        Let us try to find the Taylor series of $\cos x$ about $\frac{17 \pi}{4}$. This gives:
        \begin{align}
            f(x)=\cos x && f\left(\frac{17\pi}{4}\right) = \frac{1}{\sqrt{2}} \\ 
            f'(x)=-\sin x && f'\left(\frac{17\pi}{4}\right) = -\frac{1}{\sqrt{2}} \\ 
            f''(x)=-\cos x && f''\left(\frac{17\pi}{4}\right) = -\frac{1}{\sqrt{2}} \\ 
            f'''(x)=\sin x && f'''\left(\frac{17\pi}{4}\right) = \frac{1}{\sqrt{2}} \\ 
            f''''(x)=\cos x && f''''\left(\frac{17\pi}{4}\right) = \frac{1}{\sqrt{2}}
        \end{align}
    \end{example}
    \begin{example}
        We have already seen that:
        \begin{equation}
            \ln(1+x)=\sum_{n=1}^\infty \frac{(-1)^{n+1}x^n}{n} = x - \frac{x^2}{2} + \frac{x^3}{3} - \cdots
        \end{equation}
        fpr $-1<x \le 1$. We can verify this by verifying coefficients:
        \begin{align}
            f(x) &= \ln(1+x) \\ 
            f'(x) &= \frac{1}{1+x} \\ 
            f''(x) &= -\frac{1}{(1+x)^2} \\ 
            f'''(x) &= \frac{2}{(1+x)^3} \\ 
            f''''(x) &= \frac{-3!}{(1+x)^4} \\ 
            f^{(n)}(x) &= (-1)^{n+1} \frac{(n-1)!}{(1+x)^n}
        \end{align}
        Suppose we wish to bound the $n^\text{th}$ derivative using the remainder function:
        \begin{align}
            R_n &= \frac{1}{n!}\int_0^x f^{(n+1)}(t)(x-t)^n \dd{t} \\ 
            &= \frac{1}{n!}\int_0^x (-1)^{n+2} \frac{n!}{(1+t)^{n+1}}(x-t)^n \dd{t} \\ 
            &= (-1)^n \int_0^x \frac{(x-t)^n}{(1+t)^{n+1}}\dd{t}
        \end{align}
        Let us work with nonzero values of $x$: $0 \le x \le 1$. Then:
        \begin{align}
            |R_n(x)| &= \int_0^x \frac{(x-t)^n}{(1+t)^{n+1}} \dd{t} \\ 
            &\le \int_0^x (x-t)^n \dd{t} & (1+t)>1 \\ 
            &= \frac{x^{n+1}}{n+1}
        \end{align}
        As $n\to\infty$, this approaches zero. Now let $-1<x<0$. Then:
        \begin{align}
            |R_n(x)| &= \left|\int_0^x \frac{(x-t)^n}{(1+t)^{n+1}} \dd{t}\right| \\ 
            &= \int_x^0 \left(\frac{t-x}{1+t}\right)^n \frac{\dd{t}}{1+t}
        \end{align}
        Note that from the mean value theorem, a number $z$ exists, where $x<z<0$ such that\footnote{
            To see it explicitly, we can interpret the function as the area under the curve from $x$ to $0$ of: $\frac{(t-x)^n}{(1+t)^{n+1}}$. The mean value theorem tells us that the average height of this function has to occur at a value of $t=z$ where $x<z<0$ and the total area can be represented as the average height (at $t=z$) multiplied by the width, which is $0-x=-x$ (note that since $x$ is negative, we can interpret this as multiplying it by $-1$ to get a positive area).
        }:
        \begin{equation}
            \int_x^0 \left(\frac{t-x}{1+t}\right)^n \frac{\dd{t}}{1+t} = \left(\frac{z-x}{1+z}\right)^n \left(\frac{-x}{1+z}\right)
        \end{equation}
        Now $|x|<1$ so $|x|-|z| < 1 - |z|$. This implies:
        \begin{align}
            \frac{|x|-|z|}{1-|z|} &< 1 \\
            \frac{-x+z}{1+z} &< 1 
        \end{align}
        We then have the limit:
        \begin{equation}
            \lim_{n\to 0} \left(\frac{z-x}{1+z}\right)^n = 0
        \end{equation}
        and therefore:
        \begin{equation}
            R_n(x) \to 0
        \end{equation}
        as $n\to \infty$.
    \end{example}
    \item It is possible to multiply and divide different power series
    \begin{example}
        Suppose we have the function $\frac{e^x}{1-x}$. Then the power series is given as:
        \begin{align}
            &= \left(1 + x + \frac{x^2}{2}+\cdots\right)(1+x+x^2+\cdots) \\ 
            &= 1 + 2x + \frac{5}{2}x^2 + \frac{16}{6}x^3 + \cdots 
        \end{align}
    \end{example}
    \begin{example}
        We can determine the power expansion for $\tan x$ by using long division. We have:
        \begin{align}
            \tan x &= \frac{\sin x}{\cos x} \\ 
            &= \frac{x-x^3/3! + x^5/5! + \cdots}{1-x^2/2 + x^4/4! + \cdots} \\ 
            &= x + \frac{x^3}{2} + \frac{2}{15}x^5 + \cdots 
        \end{align}
        which for obvious reasons, I have omitted the long division steps. The radius of convergence is $|x|<R=\frac{\pi}{2}$ since the function diverges at $\tan \frac{\pi}{2}$.
    \end{example}
\end{itemize}